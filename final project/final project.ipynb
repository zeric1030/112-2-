{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T09:58:54.516890Z",
     "start_time": "2024-06-01T09:58:48.668644Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install google-api-python-client jieba torch transformers datasets",
   "id": "525cb5ec83cafb33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (2.131.0)\n",
      "Requirement already satisfied: jieba in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (0.42.1)\n",
      "Requirement already satisfied: torch in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (2.19.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client) (2.29.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client) (2.19.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.23.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zeric\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-01T13:12:13.727292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# flask應用\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "import os\n",
    "import json\n",
    "import googleapiclient.discovery\n",
    "import jieba\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import random\n",
    "\n",
    "# 設置環境變量以防止 OpenMP 衝突\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "os.environ['KMP_INIT_AT_FORK'] = 'FALSE'\n",
    "\n",
    "# 設置日志級別\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ],
   "id": "276434b8e368b4b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T11:19:11.063310Z",
     "start_time": "2024-06-01T11:19:11.057013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)  # 允許跨域請求\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 初始化 YouTube API 客戶端\n",
    "def get_youtube_client(api_key):\n",
    "    return googleapiclient.discovery.build('youtube', 'v3', developerKey=api_key)\n",
    "# 抓取頂層留言的回覆\n",
    "def get_comment_replies(parent_id, youtube):\n",
    "    replies = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.comments().list(\n",
    "            part=\"snippet\",\n",
    "            parentId=parent_id,\n",
    "            pageToken=next_page_token,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            reply = item['snippet']['textDisplay']\n",
    "            replies.append(reply)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return replies\n"
   ],
   "id": "4fdfd96ed7244e1d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T11:19:44.370681Z",
     "start_time": "2024-06-01T11:19:44.367229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 抓取影片的所有留言及其回覆\n",
    "\n",
    "def get_video_comments(video_id, api_key):\n",
    "    youtube = get_youtube_client(api_key)\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(top_comment)\n",
    "\n",
    "            # 抓取這個頂層留言的所有回覆\n",
    "            total_reply_count = item['snippet']['totalReplyCount']\n",
    "            if (total_reply_count > 0):\n",
    "                parent_id = item['id']\n",
    "                replies = get_comment_replies(parent_id, youtube)\n",
    "                comments.extend(replies)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n"
   ],
   "id": "3757855a4482141",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T11:20:53.647134Z",
     "start_time": "2024-06-01T11:20:53.640090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 jieba 進行留言分詞\n",
    "def segment_comments(comments):\n",
    "    segmented_comments = [' '.join(jieba.lcut(comment)) for comment in comments]\n",
    "    return segmented_comments\n",
    "# 訓練模型\n",
    "\n",
    "def train_model(train_texts, train_labels, model_save_path):\n",
    "    model_name = 'bert-base-chinese'\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "\n",
    "    # 分詞和編碼\n",
    "    logging.info(\"Tokenizing the data\")\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # 創建數據集\n",
    "    train_dataset = Dataset.from_dict({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': train_labels\n",
    "    })\n",
    "\n",
    "    # 設置訓練參數\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_save_path,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,  # 每隔 10 步打印一次日志\n",
    "    )\n",
    "\n",
    "    # 使用 Trainer 訓練模型\n",
    "    logging.info(\"Starting training\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    # 保存模型\n",
    "    trainer.save_model(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    \n",
    "    return model\n"
   ],
   "id": "3652047c471e9144",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加載模型\n",
    "def load_model(model_path):\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "# 預測情緒\n",
    "def predict_emotions(model, tokenizer, comments):\n",
    "    # 分詞處理留言\n",
    "    inputs = tokenizer(comments, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # 進行預測\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "    return predictions\n",
    "\n"
   ],
   "id": "c7486115d35908b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 主程式\n",
    "if __name__ == \"__main__\":\n",
    "    # 計時開始\n",
    "    logging.info(\"Starting the script\")\n",
    "    tStart = time.time()\n",
    "\n",
    "    api_key = \"AIzaSyAYu6KqHx8E96iIM96WD5saOdF2RbfoQmE\"  # 替換為你的 YouTube Data API v3 密鑰\n",
    "    video_url = input(\"請輸入影片 URL: \")\n",
    "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # 確保只取到 video_id\n",
    "\n",
    "    # 爬取留言\n",
    "    logging.info(\"Fetching comments\")\n",
    "    comments = get_video_comments(video_id, api_key)\n",
    "\n",
    "    # 斷句處理\n",
    "    logging.info(\"Segmenting comments\")\n",
    "    segmented_comments = segment_comments(comments)\n",
    "\n",
    "    # 訓練模型（假設您有標記好的數據集）\n",
    "    # 這裡使用假數據，您應該替換為實際的訓練數據\n",
    "    train_texts = []  # 請替換為實際的訓練文本\n",
    "    train_labels = []  # 請替換為實際的標籤\n",
    "    with open(\"trainword.json\") as f:\n",
    "        data = json.load(f)\n",
    "    cnt = 0\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            x = random.random()\n",
    "            if x < 0.0034:\n",
    "                train_texts.append(j[0])\n",
    "                train_labels.append(int(j[1]))\n",
    "    logging.info(\"Checking for existing model\")\n",
    "    model_save_path = './trained_model'\n",
    "\n",
    "    if os.path.exists(model_save_path):\n",
    "        logging.info(\"Loading existing model\")\n",
    "        model, tokenizer = load_model(model_save_path)\n",
    "    else:\n",
    "        logging.info(\"Training model\")\n",
    "        print(\"train size:\", len(train_texts))\n",
    "        model = train_model(train_texts, train_labels, model_save_path)\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "    # 進行情緒預測\n",
    "    logging.info(\"Predicting emotions\")\n",
    "    predictions = predict_emotions(model, tokenizer, segmented_comments)\n",
    "\n",
    "    # 輸出預測結果\n",
    "    for idx, (comment, prediction) in enumerate(zip(comments, predictions)):\n",
    "        print(f\"Comment {idx + 1}: {comment}\")\n",
    "        print(f\"Emotion Prediction: {prediction}\")\n",
    "        print(\"----------------------\")\n",
    "\n",
    "    # 計時結束\n",
    "    tEnd = time.time()\n",
    "\n",
    "    # 輸出程式執行的時間\n",
    "    logging.info(f\"Execution took {tEnd - tStart} seconds.\")\n"
   ],
   "id": "2f9871ea7cd06679"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
